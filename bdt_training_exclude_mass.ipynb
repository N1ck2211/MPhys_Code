{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import re\n",
    "import os\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('all_outputs.csv')\n",
    "data_no_mass = data.drop(columns='jj_m')\n",
    "# data_no_mass.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Looking at the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Size of data: {}'.format(data_no_mass.shape))\n",
    "print('Number of events: {}'.format(data_no_mass.shape[0]))\n",
    "print('Number of columns: {}'.format(data_no_mass.shape[1]))\n",
    "\n",
    "print ('\\nList of features in dataset:')\n",
    "for col in data_no_mass.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of signal events: {}'.format(len(data_no_mass[data_no_mass.label == 1])))\n",
    "print('Number of background events: {}'.format(len(data_no_mass[data_no_mass.label == 0])))\n",
    "print('Fraction signal: {}'.format(len(data_no_mass[data_no_mass.label == 1])/(float)(len(data_no_mass[data_no_mass.label == 1]) + len(data_no_mass[data_no_mass.label == 0]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Formatting the data for use with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shuf_data = data_no_mass.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shuf_data['label'] = data_no_mass.label.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Taking 70% of data for training set, 15% for evaluation set, and 15% for test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "no_events = shuf_data.shape[0]\n",
    "no_training = int(0.8 * no_events)\n",
    "\n",
    "training_set = shuf_data[:no_training]\n",
    "test_set = shuf_data[no_training:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of training samples: {}'.format(len(training_set)))\n",
    "print('Number of testing samples: {}'.format(len(test_set)))\n",
    "\n",
    "print('\\nNumber of signal events in training set: {}'.format(len(training_set[training_set.label == 1])))\n",
    "print('Number of background events in training set: {}'.format(len(training_set[training_set.label == 0])))\n",
    "print('Fraction signal: {}'.format(len(training_set[training_set.label == 1])/(float)(len(training_set[training_set.label == 1]) + len(training_set[training_set.label == 0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# training_set.label.cat.codes\n",
    "# print(training_set.label.cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Creating DMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feature_names = data_no_mass.columns[0:-1]  # skip the final collumn as it is the label\n",
    "# print(feature_names)\n",
    "train = xgb.DMatrix(data=training_set[feature_names],label=training_set.label.cat.codes,\n",
    "                    missing=-999.0,feature_names=feature_names)\n",
    "test = xgb.DMatrix(data=test_set[feature_names],label=test_set.label.cat.codes,\n",
    "                   missing=-999.0,feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of training samples: {}'.format(train.num_row()))\n",
    "print('Number of testing samples: {}'.format(test.num_row()))\n",
    "\n",
    "print('\\nNumber of signal events in training set: {}'.format(len(np.where(train.get_label())[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Hyperparmameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eta_range = np.arange(0.01, 0.91, 0.01)\n",
    "max_depth_range = np.arange(2, 11, 1)\n",
    "min_child_range = np.arange(0, 5.01, 0.01)\n",
    "subsample_range = np.arange(0.01, 1.01, 0.01)\n",
    "colsample_range = np.arange(0.1, 1.01, 0.01)\n",
    "lambda_range = np.arange(0.1, 10.1, 0.1)\n",
    "gamma_range = np.arange(0, 5.01, 0.01)\n",
    "\n",
    "rmse_outputs = np.zeros(len(gamma_range))\n",
    "\n",
    "# print(gamma_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# regex pattern to find floats in evaluator string\n",
    "# float_pattern = r'\\d+\\.\\d+'\n",
    "\n",
    "# for i in range(len(gamma_range)):\n",
    "#     print(i)\n",
    "#     param = {}\n",
    "\n",
    "#     # Booster parameters\n",
    "#     param['eta']              = 0.1 # learning rate\n",
    "#     param['max_depth']        = 6  # maximum depth of a tree\n",
    "#     param['subsample']        = 1 # fraction of events to train tree on\n",
    "#     param['colsample_bytree'] = 0.8 # fraction of features to train tree on\n",
    "#     param['gamma'] = gamma_range[i]  # Minimum loss reduction\n",
    "\n",
    "#     # L2 regularization\n",
    "#     param['lambda'] = 3\n",
    "\n",
    "#     # Learning task parameters\n",
    "#     param['objective']   = 'binary:logistic' # objective function\n",
    "#     param['eval_metric'] = 'error'           # evaluation metric for cross validation\n",
    "#     param = list(param.items()) + [('eval_metric', 'logloss')] + [('eval_metric', 'rmse')]\n",
    "\n",
    "#     num_trees = 250  # number of trees to make\n",
    "\n",
    "#     eval_booster = xgb.train(param, train, num_boost_round=num_trees)\n",
    "#     eval_res = eval_booster.eval(evaluation)\n",
    "\n",
    "#     result = float(re.findall(float_pattern, eval_res)[0])\n",
    "#     rmse_outputs[i] = result\n",
    "\n",
    "# print(rmse_outputs)\n",
    "# os.system(\"say beep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plt.plot(gamma_range, rmse_outputs, 'o-', color='midnightblue')\n",
    "# plt.title('RMSE vs Gamma')\n",
    "# plt.xlabel('Gamma')\n",
    "# plt.ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     'eta':eta_range,\n",
    "#     'max_depth':max_depth_range, \n",
    "#     'gamma':gamma_range,  \n",
    "#     'subsample':subsample_range,\n",
    "#     'min_child_weight':min_child_range,\n",
    "#     'colsample_bytree':colsample_range, \n",
    "#     'objective': ['binary:logistic'],\n",
    "#     'eval_metric': ['rmse'],\n",
    "#     'lambda':lambda_range,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cla = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_search = RandomizedSearchCV(cla, param_distributions=params,n_iter=20, cv=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #train test split with randomization performed (although randomization is not necessary)\n",
    "# hyperparam_training_set = shuf_data[:no_training].label.astype(int)\n",
    "# X_train, y_train  = training_set.iloc[:,:-1], training_set.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# random_search.fit(X_train, y_train)\n",
    "# os.system(\"say bing bong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper = random_search.best_params_\n",
    "# hyper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {}\n",
    "\n",
    "# Booster parameters\n",
    "param['eta']              = 0.16 # learning rate\n",
    "param['min_child_weight'] = 3.45\n",
    "param['max_depth']        = 6  # maximum depth of a tree\n",
    "param['subsample']        = 0.46 # fraction of events to train tree on\n",
    "param['colsample_bytree'] = 0.8599999999999995 # fraction of features to train tree on\n",
    "param['gamma'] = 1.42\n",
    "\n",
    "# L2 regularization\n",
    "param['lambda'] = 5.0\n",
    "\n",
    "# Learning task parameters\n",
    "param['objective']   = 'binary:logistic' # objective function\n",
    "param['eval_metric'] = 'error'           # evaluation metric for cross validation\n",
    "param = list(param.items()) + [('eval_metric', 'logloss')] + [('eval_metric', 'rmse')]\n",
    "\n",
    "num_trees = 600  # number of trees to make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "booster = xgb.train(param,train, num_boost_round=num_trees, evals=[(test, 'test')], early_stopping_rounds=10)\n",
    "os.system(\"say bing bong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(booster.eval(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictions = booster.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "att = booster.attributes()\n",
    "att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# booster_df = booster.trees_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_tree = booster.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(best_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# selected_feature_df = booster_df[booster_df['Feature'] == 'jj_m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# selected_feature_df[selected_feature_df['Tree'] == 999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plot all predictions (both signal and background)\n",
    "plt.figure()\n",
    "plt.hist(predictions,bins=np.linspace(0,1,50),histtype='step',color='darkgreen',label='All events')\n",
    "# make the plot readable\n",
    "plt.xlabel('Prediction from BDT',fontsize=12)\n",
    "plt.ylabel('Events',fontsize=12)\n",
    "plt.legend(frameon=False)\n",
    "\n",
    "# plot signal and background separately\n",
    "plt.figure()\n",
    "plt.hist(predictions[test.get_label().astype(bool)],bins=np.linspace(0,1,50),\n",
    "         histtype='step',color='midnightblue',label='signal')\n",
    "plt.hist(predictions[~(test.get_label().astype(bool))],bins=np.linspace(0,1,50),\n",
    "         histtype='step',color='firebrick',label='background')\n",
    "# make the plot readable\n",
    "plt.xlabel('Prediction from BDT',fontsize=12)\n",
    "plt.ylabel('Events',fontsize=12)\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# choose score cuts:\n",
    "cuts = np.linspace(0,1,500)\n",
    "nsignal = np.zeros(len(cuts))\n",
    "nbackground = np.zeros(len(cuts))\n",
    "for i,cut in enumerate(cuts):\n",
    "    nsignal[i] = len(np.where(predictions[test.get_label().astype(bool)] > cut)[0])\n",
    "    nbackground[i] = len(np.where(predictions[~(test.get_label().astype(bool))] > cut)[0])\n",
    "\n",
    "# plot efficiency vs. purity (ROC curve)\n",
    "plt.figure()\n",
    "plt.plot(nsignal/len(test_set[test_set.label == 1]),nsignal/(nsignal + nbackground),'o-',color='blueviolet')\n",
    "# make the plot readable\n",
    "plt.xlabel('Efficiency',fontsize=12)\n",
    "plt.ylabel('Purity',fontsize=12)\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(booster,grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib\n",
    "\n",
    "# xgb.plot_tree(booster, num_trees=227, rankdir='LR')\n",
    "# fig = matplotlib.pyplot.gcf()\n",
    "# fig.set_size_inches(150, 100)\n",
    "# fig.savefig('tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(training_set.jet_e_2[training_set.label == 1],bins=np.linspace(0,150,150),\n",
    "         histtype='step',color='midnightblue',label='signal')\n",
    "plt.hist(training_set.jet_e_2[training_set.label == 0],bins=np.linspace(0,150,150),\n",
    "         histtype='step',color='firebrick',label='background')\n",
    "\n",
    "plt.xlabel('jet_e_2',fontsize=12)\n",
    "plt.ylabel('Events',fontsize=12)\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(training_set.reco_q_1[training_set.label == 0],training_set.reco_q_2[training_set.label == 0],\n",
    "         'o',markersize=1.5,color='firebrick',markeredgewidth=0,alpha=0.8,label='background')\n",
    "plt.plot(training_set.reco_q_1[training_set.label == 1],training_set.reco_q_2[training_set.label == 1],\n",
    "         'o',markersize=1.5,color='mediumblue',markeredgewidth=0,alpha=0.8,label='signal')\n",
    "\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('reco_g_1',fontsize=12)\n",
    "plt.ylabel('reco_g_2',fontsize=12)\n",
    "plt.legend(frameon=False,numpoints=1,markerscale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(training_set.jet_e_1[training_set.label == 0],training_set.jet_e_2[training_set.label == 0],\n",
    "         'o',markersize=1,color='firebrick',markeredgewidth=0,alpha=0.8,label='background')\n",
    "plt.plot(training_set.jet_e_1[training_set.label == 1],training_set.jet_e_2[training_set.label == 1],\n",
    "         'o',markersize=1,color='mediumblue',markeredgewidth=0,alpha=0.8,label='signal')\n",
    "\n",
    "plt.xlim(0,100)\n",
    "plt.ylim(0,100)\n",
    "plt.xlabel('jet_e_1',fontsize=12)\n",
    "plt.ylabel('jet_e_2',fontsize=12)\n",
    "plt.legend(frameon=False,numpoints=1,markerscale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(training_set.jet_nchad_1[training_set.label == 0],training_set.jet_nchad_2[training_set.label == 0],\n",
    "         'o',markersize=2,color='firebrick',markeredgewidth=0,alpha=0.8,label='background')\n",
    "plt.plot(training_set.jet_nchad_1[training_set.label == 1],training_set.jet_nchad_2[training_set.label == 1],\n",
    "         'o',markersize=2,color='mediumblue',markeredgewidth=0,alpha=0.8,label='signal')\n",
    "\n",
    "plt.xlim(0, 60)\n",
    "plt.ylim(0, 50)\n",
    "plt.xlabel('reco_g_1',fontsize=12)\n",
    "plt.ylabel('reco_g_2',fontsize=12)\n",
    "plt.legend(frameon=False,numpoints=1,markerscale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}