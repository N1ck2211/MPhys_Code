{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pydot\n",
    "%pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import keras_tuner\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('full_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headings = data.columns.to_list()\n",
    "print(len(headings))\n",
    "headings_without_label = headings.pop(19)\n",
    "print(len(headings))\n",
    "headings.append('label')\n",
    "print(headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[headings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.drop(columns=data.columns[0], axis=1,  inplace=True)\n",
    "\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_high_glu = data[data.scoresum_g > 1.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuf_data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_events = shuf_data.shape[0]\n",
    "no_training = int(0.7 * no_events)\n",
    "no_val = int(no_training + (0.15 * no_events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = shuf_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:, 0:28]\n",
    "y = dataset[:, 28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train\n",
    "X_train = X[:no_training]\n",
    "X_val = X[no_training:no_val]\n",
    "X_test = X[no_val:]\n",
    "\n",
    "y_train = y[:no_training]\n",
    "y_val = y[no_training:no_val]\n",
    "y_test = y[no_val:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # tuning number of layers:\n",
    "    for i in range(hp.Int('num_layers', 1, 3)):\n",
    "        model.add(Dense(units=hp.Int(f'units{i}', min_value=10, max_value=80, step=10),\n",
    "                        activation=hp.Choice('activation', ['relu', 'tanh']),\n",
    "                       )\n",
    "                 )\n",
    "    \n",
    "    if hp.Boolean('dropout'):\n",
    "        model.add(Dropout(rate=0.2))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #Add learning rate?\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return(model)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(hypermodel=build_model, objective='val_accuracy', max_trials=5, \n",
    "                                 executions_per_trial=1, overwrite=True, directory='./NN_traing_res',\n",
    "                                 project_name='res_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(X_train, y_train, epochs=100, batch_size=500,  validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model With Best Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(40, activation='relu', name='ReLu-1'))\n",
    "model.add(Dense(10, activation='relu', name='ReLu-2'))\n",
    "model.add(Dense(10, activation='relu', name='ReLu-3'))\n",
    "model.add(Dense(1, activation='sigmoid', name='Sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "# round predictions \n",
    "rounded = [round(x[0]) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions with the model\n",
    "predictions = (model.predict(X_test) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    " print('%s => %d (expected %d)' % (X_test[i].tolist(), predictions[i], y_test[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all predictions (both signal and background)\n",
    "plt.figure()\n",
    "plt.hist(predictions, bins=np.linspace(0,1,50),histtype='step',color='darkgreen',label='All events')\n",
    "# make the plot readable\n",
    "plt.xlabel('Prediction from NN',fontsize=12)\n",
    "plt.ylabel('Events',fontsize=12)\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot signal and background separately\n",
    "plt.figure()\n",
    "plt.hist(predictions[y_test.astype(bool)],bins=np.linspace(0,1,50),\n",
    "         histtype='step',color='midnightblue',label='signal')\n",
    "plt.hist(predictions[~(y_test.astype(bool))],bins=np.linspace(0,1,50),\n",
    "         histtype='step',color='firebrick',label='background')\n",
    "# make the plot readable\n",
    "plt.xlabel('Prediction from NN',fontsize=12)\n",
    "plt.ylabel('Events',fontsize=12)\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, sig_bins = np.histogram(predictions[y_test.astype(bool)],bins=np.linspace(0,1,50))\n",
    "bkgrnd, back_bins = np.histogram(predictions[~(y_test.astype(bool))],bins=np.linspace(0,1,50))\n",
    "\n",
    "sig_sf = 10 * 7.38400e-05\n",
    "back_sf = 10 * 363\n",
    "\n",
    "plt.hist(sig_bins[:-1], sig_bins, weights=sig_sf*signal, histtype='step',color='midnightblue',label='signal')\n",
    "plt.hist(back_bins[:-1], back_bins, weights=back_sf*bkgrnd, histtype='step',color='firebrick',label='background')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Prediction from NN',fontsize=12)\n",
    "plt.ylabel('Events',fontsize=12)\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_score = (model.predict(X_test)).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all predictions (both signal and background)\n",
    "plt.figure()\n",
    "plt.hist(prediction_score, bins=np.linspace(0,1,50),histtype='step',color='darkgreen',label='All events')\n",
    "# make the plot readable\n",
    "plt.xlabel('Prediction from NN',fontsize=12)\n",
    "plt.ylabel('Events',fontsize=12)\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot signal and background separately\n",
    "plt.figure()\n",
    "plt.hist(prediction_score[y_test.astype(bool)],bins=np.linspace(0,1,50),\n",
    "         histtype='step',color='midnightblue',label='signal')\n",
    "plt.hist(prediction_score[~(y_test.astype(bool))],bins=np.linspace(0,1,50),\n",
    "         histtype='step',color='firebrick',label='background')\n",
    "# make the plot readable\n",
    "plt.xlabel('Prediction from NN',fontsize=12)\n",
    "plt.ylabel('Events',fontsize=12)\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, sig_bins = np.histogram(prediction_score[y_test.astype(bool)],bins=np.linspace(0,1,50))\n",
    "bkgrnd, back_bins = np.histogram(prediction_score[~(y_test.astype(bool))],bins=np.linspace(0,1,50))\n",
    "\n",
    "sig_sf = 10 * 7.38400e-05\n",
    "back_sf = (10 * 363) \n",
    "\n",
    "plt.hist(sig_bins[:-1], sig_bins, weights=sig_sf*signal, histtype='step',color='midnightblue',label='signal')\n",
    "plt.hist(back_bins[:-1], back_bins, weights=back_sf*bkgrnd, histtype='step',color='firebrick',label='background')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Prediction from NN',fontsize=12)\n",
    "plt.ylabel('Events',fontsize=12)\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose score cuts:\n",
    "cuts = np.linspace(0,1,500)\n",
    "nsignal = np.zeros(len(cuts))\n",
    "nbackground = np.zeros(len(cuts))\n",
    "\n",
    "for i,cut in enumerate(cuts):\n",
    "    nsignal[i] = len(np.where(prediction_score[y_test.astype(bool)] > cut)[0])\n",
    "    nbackground[i] = len(np.where(prediction_score[~(y_test.astype(bool))] > cut)[0])\n",
    "\n",
    "\n",
    "# plot efficiency vs. purity (ROC curve)\n",
    "plt.figure()\n",
    "plt.plot(nsignal/len(X_test[y_test.astype(bool) == 1]),nsignal/(nsignal + nbackground),'o-',color='blueviolet')\n",
    "# make the plot readable\n",
    "plt.xlabel('Efficiency',fontsize=12)\n",
    "plt.ylabel('Purity',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Zoom in view of the upper left corner.\n",
    "plt.figure()\n",
    "plt.xlim(0.85, 1.0)\n",
    "plt.ylim(0.85, 1.0)\n",
    "# plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(nsignal/len(X_test[y_test.astype(bool) == 1]),nsignal/(nsignal + nbackground),'o-',color='blueviolet', markersize=1)\n",
    "plt.xlabel('Efficiency',fontsize=12)\n",
    "plt.ylabel('Purity',fontsize=12)\n",
    "plt.title('ROC curve (zoomed in at top right)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
