{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import os\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('full_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Looking at the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Size of data: {}'.format(data.shape))\n",
    "print('Number of events: {}'.format(data.shape[0]))\n",
    "print('Number of columns: {}'.format(data.shape[1]))\n",
    "\n",
    "print ('\\nList of features in dataset:')\n",
    "for col in data.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headings = data.columns.to_list()\n",
    "# print(len(headings))\n",
    "# headings_without_label = headings.pop(19)\n",
    "# print(len(headings))\n",
    "# headings.append('label')\n",
    "# print(headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=data.columns[0], axis=1,  inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv('full_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of signal events: {}'.format(len(data[data.label == 1])))\n",
    "print('Number of background events: {}'.format(len(data[data.label == 0])))\n",
    "print('Fraction signal: {}'.format(len(data[data.label == 1])/(float)(len(data[data.label == 1]) + len(data[data.label == 0]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_high_glu = data[data.reco_g_1 > 0.7]\n",
    "data_high_glu = data_high_glu[data_high_glu.reco_g_2 > 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.hist(data_high_glu.jj_pt_2[data.label == 1],bins=np.linspace(0, 100, 100),\n",
    "#          histtype='step',color='midnightblue',label='signal')\n",
    "# plt.hist(data_high_glu.jj_pt_2[data.label == 0],bins=np.linspace(0, 100, 100),\n",
    "#          histtype='step',color='firebrick',label='background')\n",
    "\n",
    "# plt.xlabel('feature',fontsize=12)\n",
    "# plt.ylabel('Events',fontsize=12)\n",
    "# plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signal, sig_bins = np.histogram(data_high_glu.jet_m_2[data.label == 1],bins=np.linspace(0, 100, 100))\n",
    "# bkgrnd, back_bins = np.histogram(data_high_glu.jet_m_2[data.label == 0],bins=np.linspace(0, 100, 100))\n",
    "\n",
    "# sig_sf = 10 * 7.38400e-05\n",
    "# back_sf = (10 * 363) / 1.333318333\n",
    "\n",
    "# plt.hist(sig_bins[:-1], sig_bins, weights=sig_sf*signal, histtype='step',color='midnightblue',label='signal')\n",
    "# plt.hist(back_bins[:-1], back_bins, weights=back_sf*bkgrnd, histtype='step',color='firebrick',label='background')\n",
    "\n",
    "# plt.yscale('log')\n",
    "# plt.xlabel('Feature',fontsize=12)\n",
    "# plt.ylabel('Events',fontsize=12)\n",
    "# plt.legend(frameon=False)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_high_glu = data[data.reco_g_1 > 0.7]\n",
    "# data_high_glu = data[data.reco_g_2 > 0.7]\n",
    "\n",
    "# Removing the gluon scores:\n",
    "# no_score = data_high_glu.drop(columns=['reco_g_1', 'reco_g_2', 'reco_q_1', 'reco_q_2', 'reco_s_1', 'reco_s_2'])\n",
    "# no_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.hist(data_high_glu.reco_g_1[data_high_glu.label == 1],bins=np.linspace(0,1,50),\n",
    "#          histtype='step',color='midnightblue',label='signal')\n",
    "# plt.hist(data_high_glu.reco_g_1[data_high_glu.label == 0],bins=np.linspace(0,1,50),\n",
    "#          histtype='step',color='firebrick',label='background')\n",
    "\n",
    "# plt.xlabel('reco_glu_1',fontsize=12)\n",
    "# plt.ylabel('Events',fontsize=12)\n",
    "# plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Formatting the data for use with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shuf_data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "shuf_data['label'] = data.label.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Taking 80% of data for training set, 20% for test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "no_events = shuf_data.shape[0]\n",
    "no_training = int(0.8 * no_events)\n",
    "\n",
    "training_set = shuf_data[:no_training]\n",
    "test_set = shuf_data[no_training:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of training samples: {}'.format(len(training_set)))\n",
    "print('Number of testing samples: {}'.format(len(test_set)))\n",
    "\n",
    "print('\\nNumber of signal events in training set: {}'.format(len(training_set[training_set.label == 1])))\n",
    "print('Number of background events in training set: {}'.format(len(training_set[training_set.label == 0])))\n",
    "print('Fraction signal: {}'.format(len(training_set[training_set.label == 1])/(float)(len(training_set[training_set.label == 1]) + len(training_set[training_set.label == 0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# training_set.label.cat.codes\n",
    "# print(training_set.label.cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Creating DMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feature_names = shuf_data.columns[0:-1]  # skip the final collumn as it is the label\n",
    "# print(feature_names)\n",
    "train = xgb.DMatrix(data=training_set[feature_names],label=training_set.label.cat.codes,\n",
    "                    missing=-999.0,feature_names=feature_names)\n",
    "test = xgb.DMatrix(data=test_set[feature_names],label=test_set.label.cat.codes,\n",
    "                   missing=-999.0,feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of training samples: {}'.format(train.num_row()))\n",
    "print('Number of testing samples: {}'.format(test.num_row()))\n",
    "\n",
    "print('\\nNumber of signal events in training set: {}'.format(len(np.where(train.get_label())[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Hyperparmameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eta_range = np.arange(0.1, 1.0, 0.1)\n",
    "max_depth_range = np.arange(2, 9, 1)\n",
    "min_child_range = np.arange(0, 5.1, 0.1)\n",
    "subsample_range = np.arange(0.1, 1.1, 0.1)\n",
    "colsample_range = np.arange(0.1, 1.1, 0.1)\n",
    "lambda_range = np.arange(0, 10.25, 0.25)\n",
    "gamma_range = np.arange(0, 5.1, 0.1)\n",
    "\n",
    "rmse_outputs = np.zeros(len(gamma_range))\n",
    "\n",
    "no_params = len(eta_range) + len(max_depth_range) + len(min_child_range) + len(subsample_range) + len(colsample_range) + len(lambda_range) + len(gamma_range)\n",
    "\n",
    "print(no_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# # regex pattern to find floats in evaluator string\n",
    "# float_pattern = r'\\d+\\.\\d+'\n",
    "\n",
    "# for i in range(len(gamma_range)):\n",
    "#     print(i)\n",
    "#     param = {}\n",
    "\n",
    "#     # Booster parameters\n",
    "#     param['eta']              = 0.1 # learning rate\n",
    "#     param['max_depth']        = 6  # maximum depth of a tree\n",
    "#     param['subsample']        = 1 # fraction of events to train tree on\n",
    "#     param['colsample_bytree'] = 0.8 # fraction of features to train tree on\n",
    "#     param['gamma'] = gamma_range[i]  # Minimum loss reduction\n",
    "\n",
    "#     # L2 regularization\n",
    "#     param['lambda'] = 3\n",
    "\n",
    "#     # Learning task parameters\n",
    "#     param['objective']   = 'binary:logistic' # objective function\n",
    "#     param['eval_metric'] = 'error'           # evaluation metric for cross validation\n",
    "#     param = list(param.items()) + [('eval_metric', 'logloss')] + [('eval_metric', 'rmse')]\n",
    "\n",
    "#     num_trees = 250  # number of trees to make\n",
    "\n",
    "#     eval_booster = xgb.train(param, train, num_boost_round=num_trees)\n",
    "#     eval_res = eval_booster.eval(evaluation)\n",
    "\n",
    "#     result = float(re.findall(float_pattern, eval_res)[0])\n",
    "#     rmse_outputs[i] = result\n",
    "\n",
    "# print(rmse_outputs)\n",
    "# os.system(\"say beep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plt.plot(gamma_range, rmse_outputs, 'o-', color='midnightblue')\n",
    "# plt.title('RMSE vs Gamma')\n",
    "# plt.xlabel('Gamma')\n",
    "# plt.ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'eta':eta_range,\n",
    "    'max_depth':max_depth_range, \n",
    "    'gamma':gamma_range,  \n",
    "    'subsample':subsample_range,\n",
    "    'min_child_weight':min_child_range,\n",
    "    'colsample_bytree':colsample_range, \n",
    "    'objective': ['binary:logistic'],\n",
    "    'eval_metric': ['rmse'],\n",
    "    'lambda':lambda_range,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cla = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split with randomization performed (although randomization is not necessary)\n",
    "hyperparam_training_set = shuf_data[:no_training].label.astype(int)\n",
    "X_train, y_train  = training_set.iloc[:,:-1], training_set.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(cla, param_distributions=params, n_iter=30, cv=3, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random_search.fit(X_train, y_train)\n",
    "os.system(\"say bing bong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_res = random_search.cv_results_\n",
    "mean_score = hyper_res['mean_test_score']\n",
    "err = hyper_res['std_test_score']\n",
    "x_arr = np.arange(1, 31, 1)\n",
    "# hyper_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(x_arr, mean_score, yerr=err)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = random_search.best_params_\n",
    "hyper_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {}\n",
    "\n",
    "# Booster parameters\n",
    "param['eta']              = 0.1 # learning rate\n",
    "param['max_depth']        = 10  # maximum depth of a tree\n",
    "param['subsample']        = 0.8 # fraction of events to train tree on\n",
    "param['colsample_bytree'] = 0.8 # fraction of features to train tree on\n",
    "\n",
    "# Learning task parameters\n",
    "param['objective']   = 'binary:logistic' # objective function\n",
    "param['eval_metric'] = 'error'           # evaluation metric for cross validation\n",
    "param = list(param.items()) + [('eval_metric', 'logloss')] + [('eval_metric', 'rmse')]\n",
    "\n",
    "num_trees = 100  # number of trees to make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters from random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param = {}\n",
    "\n",
    "# # Booster parameters\n",
    "# param['eta']              = 0.1 # learning rate\n",
    "# param['min_child_weight'] = 1.9000000000000001\n",
    "# param['max_depth']        = 8  # maximum depth of a tree\n",
    "# param['subsample']        = 0.4 # fraction of events to train tree on\n",
    "# param['colsample_bytree'] = 0.8 # fraction of features to train tree on\n",
    "# param['gamma'] = 4.00\n",
    "\n",
    "# # L2 regularization\n",
    "# param['lambda'] = 3.7\n",
    "\n",
    "# # Learning task parameters\n",
    "# param['objective']   = 'binary:logistic' # objective function\n",
    "# param['eval_metric'] = 'error'           # evaluation metric for cross validation\n",
    "# param = list(param.items()) + [('eval_metric', 'logloss')] + [('eval_metric', 'rmse')]\n",
    "\n",
    "# num_trees = 600  # number of trees to make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "booster = xgb.train(param,train, num_boost_round=num_trees, evals=[(test, 'test')], early_stopping_rounds=10)\n",
    "os.system(\"say beep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(booster.eval(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictions = booster.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "att = booster.attributes()\n",
    "att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# booster_df = booster.trees_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "best_tree = booster.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(best_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# selected_feature_df = booster_df[booster_df['Feature'] == 'jj_m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# selected_feature_df[selected_feature_df['Tree'] == 999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plot all predictions (both signal and background)\n",
    "plt.figure()\n",
    "plt.hist(predictions,bins=np.linspace(0,1,50),histtype='step',color='darkgreen',label='All events')\n",
    "# make the plot readable\n",
    "plt.xlabel('Prediction from BDT',fontsize=12)\n",
    "plt.ylabel('Events',fontsize=12)\n",
    "plt.legend(frameon=False)\n",
    "\n",
    "# plot signal and background separately\n",
    "plt.figure()\n",
    "plt.hist(predictions[test.get_label().astype(bool)],bins=np.linspace(0,1,50),\n",
    "         histtype='step',color='midnightblue',label='signal')\n",
    "plt.hist(predictions[~(test.get_label().astype(bool))],bins=np.linspace(0,1,50),\n",
    "         histtype='step',color='firebrick',label='background')\n",
    "# make the plot readable\n",
    "plt.xlabel('Prediction from BDT',fontsize=12)\n",
    "plt.ylabel('Events',fontsize=12)\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, sig_bins = np.histogram(predictions[test.get_label().astype(bool)],bins=np.linspace(0,1,50))\n",
    "bkgrnd, back_bins = np.histogram(predictions[~(test.get_label().astype(bool))],bins=np.linspace(0,1,50))\n",
    "\n",
    "sig_sf = 10 * 7.38400e-05\n",
    "back_sf = (10 * 363) \n",
    "\n",
    "plt.hist(sig_bins[:-1], sig_bins, weights=sig_sf*signal, histtype='step',color='midnightblue',label='signal')\n",
    "plt.hist(back_bins[:-1], back_bins, weights=back_sf*bkgrnd, histtype='step',color='firebrick',label='background')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Prediction from BDT',fontsize=12)\n",
    "plt.ylabel('Events',fontsize=12)\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# choose score cuts:\n",
    "cuts = np.linspace(0,1,500)\n",
    "nsignal = np.zeros(len(cuts))\n",
    "nbackground = np.zeros(len(cuts))\n",
    "for i,cut in enumerate(cuts):\n",
    "    nsignal[i] = len(np.where(predictions[test.get_label().astype(bool)] > cut)[0])\n",
    "    nbackground[i] = len(np.where(predictions[~(test.get_label().astype(bool))] > cut)[0])\n",
    "\n",
    "# plot efficiency vs. purity (ROC curve)\n",
    "plt.figure()\n",
    "plt.plot(nsignal/len(test_set[test_set.label == 1]),nsignal/(nsignal + nbackground),'o-',color='blueviolet')\n",
    "# make the plot readable\n",
    "plt.xlabel('Efficiency',fontsize=12)\n",
    "plt.ylabel('Purity',fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Zoom in view of the upper left corner.\n",
    "plt.figure()\n",
    "plt.xlim(0.85, 1.0)\n",
    "plt.ylim(0.85, 1.0)\n",
    "# plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(nsignal/len(test_set[test_set.label == 1]),nsignal/(nsignal + nbackground),'o-',color='blueviolet')\n",
    "plt.xlabel('Efficiency',fontsize=12)\n",
    "plt.ylabel('Purity',fontsize=12)\n",
    "plt.title('ROC curve (zoomed in at top right)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xgb.plot_importance(booster,grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(training_set.jj_eta_1[training_set.label == 1],bins=np.linspace(-4,4,50),\n",
    "         histtype='step',color='midnightblue',label='signal')\n",
    "plt.hist(training_set.jj_eta_1[training_set.label == 0],bins=np.linspace(-4,4,50),\n",
    "         histtype='step',color='firebrick',label='background')\n",
    "\n",
    "plt.xlabel('jj_p_1',fontsize=12)\n",
    "plt.ylabel('Events',fontsize=12)\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(training_set.jj_p_1[training_set.label == 1],training_set.jj_e_1[training_set.label == 1],\n",
    "         'o',markersize=1.5,color='mediumblue',markeredgewidth=0,alpha=0.7,label='signal')\n",
    "plt.plot(training_set.jj_p_1[training_set.label == 0],training_set.jj_e_1[training_set.label == 0],\n",
    "         'o',markersize=1.5,color='firebrick',markeredgewidth=0,alpha=0.8,label='background')\n",
    "\n",
    "plt.xlim(10,80)\n",
    "plt.ylim(20,100)\n",
    "plt.xlabel('reco_s_1',fontsize=12)\n",
    "plt.ylabel('reco_s_2',fontsize=12)\n",
    "plt.legend(frameon=False,numpoints=1,markerscale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(training_set.reco_g_1[training_set.label == 1],training_set.reco_g_2[training_set.label == 1],\n",
    "         'o',markersize=1,color='mediumblue',markeredgewidth=0,alpha=0.8,label='signal')\n",
    "plt.plot(training_set.reco_g_1[training_set.label == 0],training_set.reco_g_2[training_set.label == 0],\n",
    "         'o',markersize=2,color='firebrick',markeredgewidth=0,alpha=1,label='background')\n",
    "\n",
    "plt.xlim(0.7,1)\n",
    "plt.ylim(0.7,1)\n",
    "plt.xlabel('reco_g_1',fontsize=12)\n",
    "plt.ylabel('reco_g_2',fontsize=12)\n",
    "plt.legend(frameon=False,numpoints=1,markerscale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(training_set.jj_m[training_set.label == 1],training_set.jj_p_2[training_set.label == 1],\n",
    "         'o',markersize=2,color='mediumblue',markeredgewidth=0,alpha=0.8,label='signal')\n",
    "plt.plot(training_set.jj_m[training_set.label == 0],training_set.jj_p_2[training_set.label == 0],\n",
    "         'o',markersize=2,color='firebrick',markeredgewidth=0,alpha=0.8,label='background')\n",
    "\n",
    "plt.xlim(0, 140)\n",
    "plt.ylim(0, 75)\n",
    "plt.xlabel('jj_m',fontsize=12)\n",
    "plt.ylabel('jj_p_2',fontsize=12)\n",
    "plt.legend(frameon=False,numpoints=1,markerscale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}